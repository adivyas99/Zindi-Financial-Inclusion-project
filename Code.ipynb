{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23524, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>bank_account</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_2</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Government Dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other relative</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Vocational/Specialised training</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_4</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Formally employed Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_5</td>\n",
       "      <td>No</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Child</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year    uniqueid bank_account location_type cellphone_access  \\\n",
       "0   Kenya  2018  uniqueid_1          Yes         Rural              Yes   \n",
       "1   Kenya  2018  uniqueid_2           No         Rural               No   \n",
       "2   Kenya  2018  uniqueid_3          Yes         Urban              Yes   \n",
       "3   Kenya  2018  uniqueid_4           No         Rural              Yes   \n",
       "4   Kenya  2018  uniqueid_5           No         Urban               No   \n",
       "\n",
       "   household_size  age_of_respondent gender_of_respondent  \\\n",
       "0               3                 24               Female   \n",
       "1               5                 70               Female   \n",
       "2               5                 26                 Male   \n",
       "3               5                 34               Female   \n",
       "4               8                 26                 Male   \n",
       "\n",
       "  relationship_with_head           marital_status  \\\n",
       "0                 Spouse  Married/Living together   \n",
       "1      Head of Household                  Widowed   \n",
       "2         Other relative     Single/Never Married   \n",
       "3      Head of Household  Married/Living together   \n",
       "4                  Child     Single/Never Married   \n",
       "\n",
       "                   education_level                   job_type  \n",
       "0              Secondary education              Self employed  \n",
       "1              No formal education       Government Dependent  \n",
       "2  Vocational/Specialised training              Self employed  \n",
       "3                Primary education  Formally employed Private  \n",
       "4                Primary education        Informally employed  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4\n",
      "-3\n",
      "-8735\n",
      "-2\n",
      "-2\n",
      "-2\n",
      "-20\n",
      "-85\n",
      "-2\n",
      "-6\n",
      "-5\n",
      "-6\n",
      "-10\n"
     ]
    }
   ],
   "source": [
    "for i in columns:\n",
    "    exec(\"print( - len(train_data.%s.unique()))\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'uniqueid', 'bank_account', 'location_type',\n",
       "       'cellphone_access', 'household_size', 'age_of_respondent',\n",
       "       'gender_of_respondent', 'relationship_with_head', 'marital_status',\n",
       "       'education_level', 'job_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countinuous - household_size, age_of_respondent\n",
    "columns_new = ['uniqueid', 'country', 'year', 'location_type',\n",
    "       'cellphone_access', 'household_size', 'age_of_respondent',\n",
    "       'gender_of_respondent', 'relationship_with_head', 'marital_status',\n",
    "       'education_level', 'job_type', 'bank_account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[columns_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8735\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-2\n",
      "-20\n",
      "-85\n",
      "-2\n",
      "-6\n",
      "-5\n",
      "-6\n",
      "-10\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "for i in columns_new:\n",
    "    exec(\"print( - len(train_data.%s.unique()))\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>bank_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uniqueid_1</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniqueid_2</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Government Dependent</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniqueid_3</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other relative</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Vocational/Specialised training</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uniqueid_4</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Formally employed Private</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uniqueid_5</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Child</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uniqueid country  year location_type cellphone_access  household_size  \\\n",
       "0  uniqueid_1   Kenya  2018         Rural              Yes               3   \n",
       "1  uniqueid_2   Kenya  2018         Rural               No               5   \n",
       "2  uniqueid_3   Kenya  2018         Urban              Yes               5   \n",
       "3  uniqueid_4   Kenya  2018         Rural              Yes               5   \n",
       "4  uniqueid_5   Kenya  2018         Urban               No               8   \n",
       "\n",
       "   age_of_respondent gender_of_respondent relationship_with_head  \\\n",
       "0                 24               Female                 Spouse   \n",
       "1                 70               Female      Head of Household   \n",
       "2                 26                 Male         Other relative   \n",
       "3                 34               Female      Head of Household   \n",
       "4                 26                 Male                  Child   \n",
       "\n",
       "            marital_status                  education_level  \\\n",
       "0  Married/Living together              Secondary education   \n",
       "1                  Widowed              No formal education   \n",
       "2     Single/Never Married  Vocational/Specialised training   \n",
       "3  Married/Living together                Primary education   \n",
       "4     Single/Never Married                Primary education   \n",
       "\n",
       "                    job_type bank_account  \n",
       "0              Self employed          Yes  \n",
       "1       Government Dependent           No  \n",
       "2              Self employed          Yes  \n",
       "3  Formally employed Private           No  \n",
       "4        Informally employed           No  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniqueid                  object\n",
       "country                   object\n",
       "year                       int64\n",
       "location_type             object\n",
       "cellphone_access          object\n",
       "household_size             int64\n",
       "age_of_respondent          int64\n",
       "gender_of_respondent      object\n",
       "relationship_with_head    object\n",
       "marital_status            object\n",
       "education_level           object\n",
       "job_type                  object\n",
       "bank_account              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "X = train_data.iloc[:,:-1].values\n",
    "y = train_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['uniqueid_1', 'Kenya', 2018, ..., 'Married/Living together',\n",
       "        'Secondary education', 'Self employed'],\n",
       "       ['uniqueid_2', 'Kenya', 2018, ..., 'Widowed',\n",
       "        'No formal education', 'Government Dependent'],\n",
       "       ['uniqueid_3', 'Kenya', 2018, ..., 'Single/Never Married',\n",
       "        'Vocational/Specialised training', 'Self employed'],\n",
       "       ...,\n",
       "       ['uniqueid_2115', 'Uganda', 2018, ..., 'Widowed',\n",
       "        'Primary education', 'Other Income'],\n",
       "       ['uniqueid_2116', 'Uganda', 2018, ..., 'Divorced/Seperated',\n",
       "        'Secondary education', 'Self employed'],\n",
       "       ['uniqueid_2117', 'Uganda', 2018, ..., 'Single/Never Married',\n",
       "        'Secondary education', 'No Income']], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #1,2,8,9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23524, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X1.fit_transform(X[:, 1])\n",
    "labelencoder_X2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X2.fit_transform(X[:, 2])\n",
    "labelencoder_X3 = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X3.fit_transform(X[:, 3])\n",
    "labelencoder_X4 = LabelEncoder()\n",
    "X[:, 4] = labelencoder_X4.fit_transform(X[:, 4])\n",
    "labelencoder_X7 = LabelEncoder()\n",
    "X[:, 7] = labelencoder_X7.fit_transform(X[:, 7])\n",
    "labelencoder_X8 = LabelEncoder()\n",
    "X[:, 8] = labelencoder_X8.fit_transform(X[:, 8])\n",
    "labelencoder_X9 = LabelEncoder()\n",
    "X[:, 9] = labelencoder_X9.fit_transform(X[:, 9])\n",
    "labelencoder_X10 = LabelEncoder()\n",
    "X[:, 10] = labelencoder_X10.fit_transform(X[:, 10])\n",
    "labelencoder_X11 = LabelEncoder()\n",
    "X[:, 11] = labelencoder_X11.fit_transform(X[:, 11])\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# One Hot encoding-->>\n",
    "onehotencoder1 = OneHotEncoder(categorical_features = [0,1,7,8,9,10])\n",
    "X = onehotencoder1.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23524, 39)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=39, units=128, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=256)`\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23524/23524 [==============================] - 5s 208us/step - loss: 0.3021 - acc: 0.8819\n",
      "Epoch 2/100\n",
      "23524/23524 [==============================] - 4s 163us/step - loss: 0.2920 - acc: 0.8860\n",
      "Epoch 3/100\n",
      "23524/23524 [==============================] - 4s 164us/step - loss: 0.2886 - acc: 0.8871\n",
      "Epoch 4/100\n",
      "23524/23524 [==============================] - 4s 163us/step - loss: 0.2862 - acc: 0.8888\n",
      "Epoch 5/100\n",
      "23524/23524 [==============================] - 4s 180us/step - loss: 0.2856 - acc: 0.8883 0s - loss: 0.2852 - acc: 0\n",
      "Epoch 6/100\n",
      "23524/23524 [==============================] - 5s 205us/step - loss: 0.2840 - acc: 0.8890 0s - loss: 0.2861 - acc:\n",
      "Epoch 7/100\n",
      "23524/23524 [==============================] - 4s 176us/step - loss: 0.2850 - acc: 0.8881\n",
      "Epoch 8/100\n",
      "23524/23524 [==============================] - 4s 189us/step - loss: 0.2824 - acc: 0.8903\n",
      "Epoch 9/100\n",
      "23524/23524 [==============================] - 4s 175us/step - loss: 0.2827 - acc: 0.8882\n",
      "Epoch 10/100\n",
      "23524/23524 [==============================] - 5s 197us/step - loss: 0.2810 - acc: 0.8881 0s - loss: 0.2812 - acc: 0.8\n",
      "Epoch 11/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2821 - acc: 0.8900\n",
      "Epoch 12/100\n",
      "23524/23524 [==============================] - 5s 197us/step - loss: 0.2796 - acc: 0.8893\n",
      "Epoch 13/100\n",
      "23524/23524 [==============================] - 4s 189us/step - loss: 0.2799 - acc: 0.8901 3s \n",
      "Epoch 14/100\n",
      "23524/23524 [==============================] - 5s 202us/step - loss: 0.2802 - acc: 0.8912\n",
      "Epoch 15/100\n",
      "23524/23524 [==============================] - 4s 184us/step - loss: 0.2787 - acc: 0.8901\n",
      "Epoch 16/100\n",
      "23524/23524 [==============================] - 5s 218us/step - loss: 0.2780 - acc: 0.8915\n",
      "Epoch 17/100\n",
      "23524/23524 [==============================] - 5s 214us/step - loss: 0.2798 - acc: 0.8905\n",
      "Epoch 18/100\n",
      "23524/23524 [==============================] - 5s 230us/step - loss: 0.2781 - acc: 0.8904\n",
      "Epoch 19/100\n",
      "23524/23524 [==============================] - 4s 167us/step - loss: 0.2770 - acc: 0.8910\n",
      "Epoch 20/100\n",
      "23524/23524 [==============================] - 4s 172us/step - loss: 0.2780 - acc: 0.8912\n",
      "Epoch 21/100\n",
      "23524/23524 [==============================] - 5s 203us/step - loss: 0.2761 - acc: 0.8920 0s - loss: 0.2775 - acc:  - ETA: 0s - loss: 0.2768 - acc: 0\n",
      "Epoch 22/100\n",
      "23524/23524 [==============================] - 4s 174us/step - loss: 0.2753 - acc: 0.8921\n",
      "Epoch 23/100\n",
      "23524/23524 [==============================] - 4s 174us/step - loss: 0.2765 - acc: 0.8915\n",
      "Epoch 24/100\n",
      "23524/23524 [==============================] - 4s 185us/step - loss: 0.2749 - acc: 0.8899\n",
      "Epoch 25/100\n",
      "23524/23524 [==============================] - 5s 199us/step - loss: 0.2765 - acc: 0.8911 0s - loss: 0.275 - ETA: 0s - loss: 0.2747 - acc: 0\n",
      "Epoch 26/100\n",
      "23524/23524 [==============================] - 5s 221us/step - loss: 0.2745 - acc: 0.8934\n",
      "Epoch 27/100\n",
      "23524/23524 [==============================] - 5s 195us/step - loss: 0.2748 - acc: 0.8937\n",
      "Epoch 28/100\n",
      "23524/23524 [==============================] - 4s 167us/step - loss: 0.2744 - acc: 0.8930\n",
      "Epoch 29/100\n",
      "23524/23524 [==============================] - 4s 170us/step - loss: 0.2735 - acc: 0.8916\n",
      "Epoch 30/100\n",
      "23524/23524 [==============================] - 4s 166us/step - loss: 0.2711 - acc: 0.8933\n",
      "Epoch 31/100\n",
      "23524/23524 [==============================] - 4s 174us/step - loss: 0.2725 - acc: 0.8928\n",
      "Epoch 32/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2718 - acc: 0.8940\n",
      "Epoch 33/100\n",
      "23524/23524 [==============================] - 4s 167us/step - loss: 0.2717 - acc: 0.8937\n",
      "Epoch 34/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2710 - acc: 0.8930\n",
      "Epoch 35/100\n",
      "23524/23524 [==============================] - 4s 165us/step - loss: 0.2718 - acc: 0.8922\n",
      "Epoch 36/100\n",
      "23524/23524 [==============================] - 4s 165us/step - loss: 0.2703 - acc: 0.8928\n",
      "Epoch 37/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2700 - acc: 0.8943\n",
      "Epoch 38/100\n",
      "23524/23524 [==============================] - 4s 165us/step - loss: 0.2714 - acc: 0.8925\n",
      "Epoch 39/100\n",
      "23524/23524 [==============================] - 4s 167us/step - loss: 0.2724 - acc: 0.8930\n",
      "Epoch 40/100\n",
      "23524/23524 [==============================] - 4s 164us/step - loss: 0.2709 - acc: 0.8938\n",
      "Epoch 41/100\n",
      "23524/23524 [==============================] - 4s 182us/step - loss: 0.2698 - acc: 0.8949 0s - loss: 0.2698 - \n",
      "Epoch 42/100\n",
      "23524/23524 [==============================] - 5s 192us/step - loss: 0.2704 - acc: 0.8947 0s - loss: 0.2699 - acc: 0.89\n",
      "Epoch 43/100\n",
      "23524/23524 [==============================] - 4s 178us/step - loss: 0.2693 - acc: 0.8939\n",
      "Epoch 44/100\n",
      "23524/23524 [==============================] - 4s 181us/step - loss: 0.2687 - acc: 0.8945\n",
      "Epoch 45/100\n",
      "23524/23524 [==============================] - 4s 183us/step - loss: 0.2681 - acc: 0.8947\n",
      "Epoch 46/100\n",
      "23524/23524 [==============================] - 4s 180us/step - loss: 0.2683 - acc: 0.8939\n",
      "Epoch 47/100\n",
      "23524/23524 [==============================] - 4s 178us/step - loss: 0.2666 - acc: 0.8953\n",
      "Epoch 48/100\n",
      "23524/23524 [==============================] - 4s 171us/step - loss: 0.2654 - acc: 0.8948\n",
      "Epoch 49/100\n",
      "23524/23524 [==============================] - 4s 186us/step - loss: 0.2658 - acc: 0.8960 0s - loss: 0.265\n",
      "Epoch 50/100\n",
      "23524/23524 [==============================] - 4s 170us/step - loss: 0.2677 - acc: 0.8948\n",
      "Epoch 51/100\n",
      "23524/23524 [==============================] - 4s 165us/step - loss: 0.2658 - acc: 0.8961\n",
      "Epoch 52/100\n",
      "23524/23524 [==============================] - 4s 164us/step - loss: 0.2655 - acc: 0.8973\n",
      "Epoch 53/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2654 - acc: 0.8964\n",
      "Epoch 54/100\n",
      "23524/23524 [==============================] - 4s 164us/step - loss: 0.2658 - acc: 0.8967\n",
      "Epoch 55/100\n",
      "23524/23524 [==============================] - 4s 163us/step - loss: 0.2666 - acc: 0.8946\n",
      "Epoch 56/100\n",
      "23524/23524 [==============================] - 4s 164us/step - loss: 0.2647 - acc: 0.8965\n",
      "Epoch 57/100\n",
      "23524/23524 [==============================] - 4s 166us/step - loss: 0.2635 - acc: 0.8970\n",
      "Epoch 58/100\n",
      "23524/23524 [==============================] - 4s 163us/step - loss: 0.2658 - acc: 0.8953\n",
      "Epoch 59/100\n",
      "23524/23524 [==============================] - 4s 180us/step - loss: 0.2651 - acc: 0.8960 2s - loss: 0.2664 - acc: 0.8 - ETA: 0s - loss: 0.2661 \n",
      "Epoch 60/100\n",
      "23524/23524 [==============================] - 4s 166us/step - loss: 0.2642 - acc: 0.8962\n",
      "Epoch 61/100\n",
      "23524/23524 [==============================] - 4s 176us/step - loss: 0.2666 - acc: 0.8950\n",
      "Epoch 62/100\n",
      "23524/23524 [==============================] - 5s 205us/step - loss: 0.2631 - acc: 0.8955 0s - loss: 0.2624 - acc: 0.895\n",
      "Epoch 63/100\n",
      "23524/23524 [==============================] - 4s 174us/step - loss: 0.2642 - acc: 0.8960\n",
      "Epoch 64/100\n",
      "23524/23524 [==============================] - 4s 169us/step - loss: 0.2640 - acc: 0.8963 1s -\n",
      "Epoch 65/100\n",
      "23524/23524 [==============================] - 4s 163us/step - loss: 0.2607 - acc: 0.8993 0s - loss: 0.2594 - a\n",
      "Epoch 66/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2630 - acc: 0.8960\n",
      "Epoch 67/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2600 - acc: 0.8968\n",
      "Epoch 68/100\n",
      "23524/23524 [==============================] - 5s 230us/step - loss: 0.2617 - acc: 0.8993 6s - l - ETA: 3s -\n",
      "Epoch 69/100\n",
      "23524/23524 [==============================] - 5s 221us/step - loss: 0.2611 - acc: 0.8962\n",
      "Epoch 70/100\n",
      "23524/23524 [==============================] - 4s 187us/step - loss: 0.2611 - acc: 0.8972 1s - loss: 0.2635 - acc: 0.895 - ETA: 1s - los\n",
      "Epoch 71/100\n",
      "23524/23524 [==============================] - 4s 178us/step - loss: 0.2618 - acc: 0.8971 0s - loss: 0.25\n",
      "Epoch 72/100\n",
      "23524/23524 [==============================] - 4s 174us/step - loss: 0.2597 - acc: 0.8987\n",
      "Epoch 73/100\n",
      "23524/23524 [==============================] - 4s 181us/step - loss: 0.2609 - acc: 0.8982\n",
      "Epoch 74/100\n",
      "23524/23524 [==============================] - 4s 165us/step - loss: 0.2609 - acc: 0.8971\n",
      "Epoch 75/100\n",
      "23524/23524 [==============================] - 4s 163us/step - loss: 0.2607 - acc: 0.8988\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23524/23524 [==============================] - 4s 179us/step - loss: 0.2621 - acc: 0.8965\n",
      "Epoch 77/100\n",
      "23524/23524 [==============================] - 5s 206us/step - loss: 0.2596 - acc: 0.8991 1s - loss: 0.2576  - ETA: 0s - loss: 0.2597 - acc: 0.8\n",
      "Epoch 78/100\n",
      "23524/23524 [==============================] - 4s 169us/step - loss: 0.2595 - acc: 0.8977\n",
      "Epoch 79/100\n",
      "23524/23524 [==============================] - 4s 167us/step - loss: 0.2601 - acc: 0.8983\n",
      "Epoch 80/100\n",
      "23524/23524 [==============================] - 4s 169us/step - loss: 0.2583 - acc: 0.8994 1s - los\n",
      "Epoch 81/100\n",
      "23524/23524 [==============================] - 4s 169us/step - loss: 0.2589 - acc: 0.8978\n",
      "Epoch 82/100\n",
      "23524/23524 [==============================] - 4s 165us/step - loss: 0.2605 - acc: 0.8982\n",
      "Epoch 83/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2586 - acc: 0.8997 0s - loss: 0.2569 \n",
      "Epoch 84/100\n",
      "23524/23524 [==============================] - 4s 167us/step - loss: 0.2566 - acc: 0.9002 0s - loss: 0.2581 -\n",
      "Epoch 85/100\n",
      "23524/23524 [==============================] - 4s 166us/step - loss: 0.2595 - acc: 0.8992\n",
      "Epoch 86/100\n",
      "23524/23524 [==============================] - 4s 169us/step - loss: 0.2582 - acc: 0.8994\n",
      "Epoch 87/100\n",
      "23524/23524 [==============================] - 4s 166us/step - loss: 0.2578 - acc: 0.9010\n",
      "Epoch 88/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2580 - acc: 0.8990\n",
      "Epoch 89/100\n",
      "23524/23524 [==============================] - 4s 169us/step - loss: 0.2565 - acc: 0.8995\n",
      "Epoch 90/100\n",
      "23524/23524 [==============================] - 4s 172us/step - loss: 0.2624 - acc: 0.8976\n",
      "Epoch 91/100\n",
      "23524/23524 [==============================] - 4s 175us/step - loss: 0.2584 - acc: 0.8987\n",
      "Epoch 92/100\n",
      "23524/23524 [==============================] - 4s 168us/step - loss: 0.2554 - acc: 0.8993\n",
      "Epoch 93/100\n",
      "23524/23524 [==============================] - 4s 191us/step - loss: 0.2570 - acc: 0.8987\n",
      "Epoch 94/100\n",
      "23524/23524 [==============================] - 5s 193us/step - loss: 0.2578 - acc: 0.8990\n",
      "Epoch 95/100\n",
      "23524/23524 [==============================] - 5s 192us/step - loss: 0.2577 - acc: 0.8989 1s - loss:  - ETA: 0s - loss: 0.2608 -\n",
      "Epoch 96/100\n",
      "23524/23524 [==============================] - 5s 198us/step - loss: 0.2580 - acc: 0.8983 0s - loss: 0.2553 \n",
      "Epoch 97/100\n",
      "23524/23524 [==============================] - 4s 187us/step - loss: 0.2555 - acc: 0.8991\n",
      "Epoch 98/100\n",
      "23524/23524 [==============================] - 5s 218us/step - loss: 0.2562 - acc: 0.9001\n",
      "Epoch 99/100\n",
      "23524/23524 [==============================] - 5s 199us/step - loss: 0.2605 - acc: 0.8989\n",
      "Epoch 100/100\n",
      "23524/23524 [==============================] - 7s 294us/step - loss: 0.2576 - acc: 0.8993 0s - loss: 0.2554 - a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'y_pred = classifier.predict(X_test)\\ny_pred = (y_pred > 0.5)\\n\\n# Making the Confusion Matrix\\nfrom sklearn.metrics import confusion_matrix\\ncm = confusion_matrix(y_test, y_pred)'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 128, init = 'uniform', activation = 'relu', input_dim = 39))\n",
    "classifier.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 256, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dropout(0.3))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X, y, batch_size = 8, nb_epoch = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "'''y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.models import load_model\\n\\nclassifier.save('Classifier_model.h5')  # creates a HDF5 file 'my_model.h5'\\ndel model  # deletes the existing model\\n\\n# returns a compiled model\\n# identical to the previous one\\nclassifier = load_model('Classifier_model.h5')\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "classifier.save('Classifier_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "classifier = load_model('Classifier_model.h5')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_json = classifier.to_json()\\nwith open(\"model.json\", \"w\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nclassifier.save_weights(\"model.h5\")\\nprint(\"Saved model to disk\")\\n\\n# load json and create model\\njson_file = open(\\'model.json\\', \\'r\\')\\nloaded_model_json = json_file.read()\\njson_file.close()\\nloaded_model = model_from_json(loaded_model_json)\\n# load weights into new model\\nloaded_model.load_weights(\"model.h5\")\\nprint(\"Loaded model from disk\")\\n \\n# evaluate loaded model on test data\\nloaded_model.compile(loss=\\'binary_crossentropy\\', optimizer=\\'rmsprop\\', metrics=[\\'accuracy\\'])\\nscore = loaded_model.evaluate(X, Y, verbose=0)\\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# serialize model to YAML\\nmodel_yaml = classifier.to_yaml()\\nwith open(\"model.yaml\", \"w\") as yaml_file:\\n    yaml_file.write(model_yaml)\\n# serialize weights to HDF5\\nclassifier.save_weights(\"model.h5\")\\nprint(\"Saved model to disk\")\\n \\n# later...\\n \\n# load YAML and create model\\nyaml_file = open(\\'model.yaml\\', \\'r\\')\\nloaded_model_yaml = yaml_file.read()\\nyaml_file.close()\\nloaded_model = model_from_yaml(loaded_model_yaml)\\n# load weights into new model\\nloaded_model.load_weights(\"model.h5\")\\nprint(\"Loaded model from disk\")\\n \\n# evaluate loaded model on test data\\nloaded_model.compile(loss=\\'binary_crossentropy\\', optimizer=\\'rmsprop\\', metrics=[\\'accuracy\\'])\\nscore = loaded_model.evaluate(X, Y, verbose=0)\\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# serialize model to YAML\n",
    "model_yaml = classifier.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns_new = ['uniqueid', 'country', 'year', 'location_type',\n",
    "       'cellphone_access', 'household_size', 'age_of_respondent',\n",
    "       'gender_of_respondent', 'relationship_with_head', 'marital_status',\n",
    "       'education_level', 'job_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test_columns_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:, 1] = labelencoder_X1.fit_transform(X_test[:, 1])\n",
    "X_test[:, 2] = labelencoder_X2.fit_transform(X_test[:, 2])\n",
    "X_test[:, 3] = labelencoder_X3.fit_transform(X_test[:, 3])\n",
    "X_test[:, 4] = labelencoder_X4.fit_transform(X_test[:, 4])\n",
    "X_test[:, 7] = labelencoder_X7.fit_transform(X_test[:, 7])\n",
    "X_test[:, 8] = labelencoder_X8.fit_transform(X_test[:, 8])\n",
    "X_test[:, 9] = labelencoder_X9.fit_transform(X_test[:, 9])\n",
    "X_test[:, 10] = labelencoder_X10.fit_transform(X_test[:, 10])\n",
    "X_test[:, 11] = labelencoder_X11.fit_transform(X_test[:, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unique_ids = X_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# One Hot encoding-->>\n",
    "X_test = onehotencoder1.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = pd.DataFrame(data={'uniqueid':test_unique_ids.reshape(10086,), 'bank_account':predictions.reshape(10086,)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "def addxcountry(x):\n",
    "    global i\n",
    "    #print(i)\n",
    "    x = x + ' x ' + str(test.iloc[i,1])\n",
    "    i+=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission['uniqueid'] = final_submission.uniqueid.map(addxcountry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
